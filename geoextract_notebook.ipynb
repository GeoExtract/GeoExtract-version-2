{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909f9f2f",
   "metadata": {},
   "source": [
    "## 0 Â· Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Install dependencies (Kaggle already has most, add extras) â”€â”€\n",
    "!pip install -q ultralytics peft bitsandbytes qwen-vl-utils \\\n",
    "    rasterio geopandas albumentations wandb transformers accelerate --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# â”€â”€ Set W&B API key from Kaggle Secrets or env â”€â”€\n",
    "# Option 1: Kaggle Secrets (recommended)\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    secrets = UserSecretsClient()\n",
    "    os.environ['WANDB_API_KEY'] = secrets.get_secret('WANDB_API_KEY')\n",
    "    print('âœ“ W&B API key loaded from Kaggle Secrets')\n",
    "except Exception:\n",
    "    print('âš  Set WANDB_API_KEY manually: os.environ[\"WANDB_API_KEY\"] = \"your-key\"')\n",
    "\n",
    "# â”€â”€ Set SpaceNet 7 data root (auto-detects Kaggle input) â”€â”€\n",
    "# Change the dataset name below to match YOUR Kaggle input dataset name\n",
    "SPACENET_DATASET_NAME = 'spacenet7'  # adjust if your dataset is named differently\n",
    "if os.path.exists(f'/kaggle/input/{SPACENET_DATASET_NAME}'):\n",
    "    os.environ['SPACENET7_ROOT'] = f'/kaggle/input/{SPACENET_DATASET_NAME}'\n",
    "    print(f'âœ“ SpaceNet 7 data root: /kaggle/input/{SPACENET_DATASET_NAME}')\n",
    "else:\n",
    "    # List available input datasets\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        available = os.listdir('/kaggle/input')\n",
    "        print(f'Available datasets: {available}')\n",
    "        print('Set os.environ[\"SPACENET7_ROOT\"] to the correct path.')\n",
    "    else:\n",
    "        print('Running locally â€” set SPACENET7_ROOT env variable.')\n",
    "\n",
    "print(f'Python: {sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Load GeoExtract config â”€â”€\n",
    "from config import CFG, IS_KAGGLE\n",
    "from utils import log_vram, free_vram\n",
    "\n",
    "print(CFG.summary())\n",
    "log_vram('startup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1d791",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 Â· Data Pipeline â€” SpaceNet 7 â†’ YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline import YOLODatasetBuilder\n",
    "\n",
    "# Build YOLO dataset from SpaceNet 7\n",
    "builder = YOLODatasetBuilder()\n",
    "dataset_yaml = builder.build()\n",
    "\n",
    "# Print stats\n",
    "stats = builder.get_stats()\n",
    "print('\\nðŸ“Š Dataset Statistics:')\n",
    "for split, s in stats.items():\n",
    "    print(f'  {split}: {s[\"images\"]} images, {s[\"total_bboxes\"]} boxes '\n",
    "          f'({s[\"avg_bboxes_per_image\"]} avg/img)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3fe16",
   "metadata": {},
   "source": [
    "## 2 Â· Synthetic QA Generation for VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a24443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa_generator import SyntheticQAGenerator\n",
    "\n",
    "qa_gen = SyntheticQAGenerator()\n",
    "qa_train_path = qa_gen.generate()\n",
    "\n",
    "# Print stats\n",
    "qa_stats = qa_gen.get_stats()\n",
    "print('\\nðŸ“Š QA Generation Statistics:')\n",
    "for split, s in qa_stats.items():\n",
    "    print(f'  {split}: {s[\"conversations\"]} conversations, '\n",
    "          f'{s[\"total_qa_turns\"]} QA turns')\n",
    "    print(f'    Density distribution: {s[\"density_distribution\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a82b3c",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Â· Phase 1: YOLO Training (Building Detection)\n",
    "\n",
    "**VRAM Budget:** ~4-6 GB  \n",
    "Training YOLOv11-nano with auto-resume capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_trainer import YOLOTrainer\n",
    "\n",
    "yolo_trainer = YOLOTrainer(dataset_yaml=dataset_yaml)\n",
    "best_yolo_weights = yolo_trainer.train()\n",
    "\n",
    "print(f'\\nâœ“ Best YOLO weights: {best_yolo_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b062e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate YOLO and get hard metrics\n",
    "yolo_metrics = yolo_trainer.validate()\n",
    "print(f'\\nðŸ“Š YOLO Metrics: {yolo_metrics}')\n",
    "\n",
    "# CRITICAL: Free YOLO from GPU before loading VLM\n",
    "yolo_trainer.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719a008",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 Â· Phase 2: VLM Training (Urban Reasoner)\n",
    "\n",
    "**VRAM Budget:** ~10-12 GB  \n",
    "Qwen2-VL-2B in 4-bit NF4 with LoRA (r=16, Î±=32).  \n",
    "Cosine LR schedule with 10% warmup.  \n",
    "Checkpoints every 500 steps â€” auto-resumes on Kaggle restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vlm_trainer import VLMTrainer\n",
    "\n",
    "vlm_trainer = VLMTrainer()\n",
    "adapter_path = vlm_trainer.train()\n",
    "\n",
    "print(f'\\nâœ“ VLM adapter saved to: {adapter_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free VLM training resources\n",
    "vlm_trainer.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07201059",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 Â· Evaluation â€” Hard Metrics for Defense\n",
    "\n",
    "Computes F1, Precision, Recall for:\n",
    "- **YOLO** â€” Building detection (IoU-based)\n",
    "- **VLM** â€” Density classification (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import GeoExtractEvaluator\n",
    "from inference import GeoExtractPipeline\n",
    "\n",
    "# Load the inference pipeline for VLM evaluation\n",
    "pipeline = GeoExtractPipeline()\n",
    "pipeline.load()\n",
    "\n",
    "# Run full evaluation\n",
    "evaluator = GeoExtractEvaluator()\n",
    "all_metrics = evaluator.run_full_evaluation(\n",
    "    dataset_yaml=dataset_yaml,\n",
    "    yolo_weights=best_yolo_weights,\n",
    "    pipeline=pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5a5a0",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 Â· Agentic Inference â€” Demo\n",
    "\n",
    "Run the dual-model pipeline on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€ Single image analysis â”€â”€\n",
    "# Pick a sample image from the validation set\n",
    "val_images = list((Path(CFG.data.root) / 'train').rglob('*.tif'))[:3]\n",
    "\n",
    "for img_path in val_images:\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Analyzing: {img_path.name}')\n",
    "    print('='*60)\n",
    "    \n",
    "    result = pipeline.analyze(img_path)\n",
    "    \n",
    "    print(f'Buildings detected: {result[\"detection\"][\"building_count\"]}')\n",
    "    print(f'Density class: {result[\"context\"][\"density_class\"]}')\n",
    "    print(f'Processing time: {result[\"processing_time_s\"]}s')\n",
    "    print(f'\\nVLM Analysis:')\n",
    "    print(result['analysis']['response'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Multi-turn conversation demo â”€â”€\n",
    "if val_images:\n",
    "    img = val_images[0]\n",
    "    history = []\n",
    "    \n",
    "    # Turn 1\n",
    "    r1 = pipeline.chat(img, history, 'How many buildings are in this image?')\n",
    "    print(f'Q1: How many buildings?')\n",
    "    print(f'A1: {r1[\"response\"][:300]}\\n')\n",
    "    history = r1['conversation_history']\n",
    "    \n",
    "    # Turn 2 â€” follow-up\n",
    "    r2 = pipeline.chat(img, history, 'What urban planning risks do you see?')\n",
    "    print(f'Q2: What urban planning risks?')\n",
    "    print(f'A2: {r2[\"response\"][:300]}\\n')\n",
    "    history = r2['conversation_history']\n",
    "    \n",
    "    # Turn 3 â€” deeper follow-up\n",
    "    r3 = pipeline.chat(img, history, 'Recommend specific interventions to improve livability.')\n",
    "    print(f'Q3: Recommend interventions')\n",
    "    print(f'A3: {r3[\"response\"][:300]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4600996",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 Â· Export for Deployment\n",
    "\n",
    "Export trained weights for FastAPI backend integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import EXPORT_DIR\n",
    "import shutil\n",
    "\n",
    "# â”€â”€ Export YOLO to ONNX â”€â”€\n",
    "from yolo_trainer import YOLOTrainer\n",
    "yt = YOLOTrainer(dataset_yaml=dataset_yaml)\n",
    "onnx_path = yt.export_for_deployment(format='onnx')\n",
    "shutil.copy2(onnx_path, EXPORT_DIR / 'yolo_building_detector.onnx')\n",
    "\n",
    "# â”€â”€ Copy VLM adapter â”€â”€\n",
    "vlm_export_dir = EXPORT_DIR / 'vlm_adapter'\n",
    "vlm_export_dir.mkdir(exist_ok=True)\n",
    "adapter_src = CFG.vlm.output_dir / 'final_adapter'\n",
    "if adapter_src.exists():\n",
    "    for f in adapter_src.iterdir():\n",
    "        shutil.copy2(f, vlm_export_dir / f.name)\n",
    "\n",
    "print(f'\\nâœ“ Exports ready at {EXPORT_DIR}:')\n",
    "for f in sorted(EXPORT_DIR.rglob('*')):\n",
    "    if f.is_file():\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f'  {f.relative_to(EXPORT_DIR)} ({size_mb:.1f} MB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17870951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "pipeline.cleanup()\n",
    "free_vram()\n",
    "print('\\nðŸŽ‰ GeoExtract v2 pipeline complete!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
